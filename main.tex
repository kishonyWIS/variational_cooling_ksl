\documentclass[twocolumn,
aps,
prx,
showpacs,
amsmath,
amssymb,
floatfix,
longbibliography,
superscriptaddress,
eprint]
{revtex4-1}

\usepackage{xcolor}
\definecolor{darkblue}{RGB}{0,0,150}
\definecolor{nightblue}{RGB}{0,0,100}

\usepackage{graphicx,mathtools,bm,bbm}
\usepackage{MnSymbol}
\usepackage[
colorlinks,
citecolor=darkblue,
linkcolor=darkblue,
urlcolor=nightblue]{hyperref}

\usepackage[english]{babel}
\usepackage[babel,kerning=true,spacing=true]{microtype}
\usepackage[utf8]{inputenc}

\usepackage{soul}

\newcommand{\erez}[1]{{\color{red}{\bf EB: #1}}}
\newcommand{\addEB}[1]{{\color{blue}{#1}}}
\newcommand{\gilad}[1]{{\color{cyan}{\bf GK: #1}}}

\newcommand{\ket}[1]{{\left|#1\right\rangle}}
\newcommand{\tket}[1]{{|#1\rangle}}
\newcommand{\bra}[1]{{\left\langle #1\right|}}
\newcommand{\tbra}[1]{{\langle #1|}}
\newcommand{\avg}[1]{{\left\langle #1\right\rangle}}
\newcommand{\tavg}[1]{{\langle #1\rangle}}
\newcommand{\dd}{\mathbf{d}}
\newcommand{\vm}{\mathbf{m}}
\newcommand{\B}{\mathbf{B}}
\newcommand{\vsigma}{\bm{\sigma}}
\newcommand{\A}{\mathbf{A}}
\newcommand{\E}{\mathbf{E}}
\newcommand{\T}{\mathcal{E}}
\newcommand{\J}{\mathbf{J}}
\newcommand{\rr}{\mathbf{r}}
\newcommand{\Tr}[1]{{\mathrm{Tr}\left[#1\right]}}
\newcommand{\defeq}{\overset{\scriptscriptstyle\mathrm{def}}{=}}
\renewcommand{\vec}[1]{{\bf #1}}
\newcommand{\vpd}{\vphantom{\dagger}}

\begin{document}

\title{Variational Cooling of a Chiral Spin Liquid: \\ Shallow-Depth Circuit Optimization for the Kitaev Honeycomb Model}

\author{Gilad Kishony}\email{gilad.kishony@weizmann.ac.il}
\affiliation{Department of Condensed Matter Physics,
Weizmann Institute of Science,
Rehovot 76100, Israel}
\author{Erez Berg}
\affiliation{Department of Condensed Matter Physics,
Weizmann Institute of Science,
Rehovot 76100, Israel}

\begin{abstract}
We present an efficient approach for preparing the ground state of the chiral phase of the Kitaev spin liquid (KSL) model using a shallow-depth quantum circuit. 
By combining the fermionic cooling approach of Ref.~\cite{Kishony_2025} with the variational optimization strategy of Ref.~\cite{song2025varicoolnonunitaryquantumvariational}, we develop a protocol that replaces the large-depth Trotterized evolution (requiring on the order of 100 steps) with an optimized circuit containing only a few layers. The protocol is trained on small momentum-space grids and demonstrates good transferability to larger system sizes. We systematically explore the performance as a function of circuit depth and training system size, showing that even with $p=5$ layers, the protocol achieves a state with a residual energy density of $0.013$ in the units of the gap.
\end{abstract}

\maketitle

\section{Introduction}

The preparation of topologically non-trivial quantum states, particularly chiral states with non-Abelian anyon excitations, remains a central challenge in quantum simulation. The chiral phase of the Kitaev spin liquid (KSL) model~\cite{kitaev2006anyons} on the honeycomb lattice provides an important test case, as it hosts emergent Majorana fermions with a non-zero Chern number and cannot be prepared by finite-depth local unitary circuits from a product state.

Recent work has demonstrated that fermionic cooling protocols can efficiently prepare such states by coupling the system to a simulated fermionic bath~\cite{Kishony_2025}. However, these protocols typically require many Trotter steps (on the order of 100) to achieve adiabatic evolution, making them challenging to implement on near-term quantum hardware. Inspired by variational quantum algorithms such as QAOA~\cite{farhiQAOA} and the Vari-Cool protocol~\cite{Kishony_2025}, we develop a variational approach that compresses the cooling evolution into a shallow-depth circuit with only a few layers while maintaining high fidelity ground state preparation.

\section{Model}

\subsection{Target Hamiltonian: Kitaev Spin Liquid}

The Kitaev spin liquid model consists of spin-$\frac{1}{2}$ degrees of freedom on a honeycomb lattice with anisotropic exchange interactions. The Hamiltonian is given by:
\begin{align}
H_{\text{KSL}}=&-\sum_{\alpha\in\{x,y,z\}}\mathcal{J}_{\alpha}\sum_{\langle\mathbf{I},\mathbf{J}\rangle\in \alpha\text{-bonds}}\sigma_{\mathbf{I}}^{\alpha}\sigma_{\mathbf{J}}^{\alpha}
\nonumber\\
&-\kappa\sum_{\langle\langle\mathbf{J},\mathbf{K},\mathbf{L}\rangle\rangle}\sigma_{\mathbf{J}}^{x}\sigma_{\mathbf{K}}^{y}\sigma_{\mathbf{L}}^{z},
\label{eq: KSL}
\end{align}
where $\mathbf{J} = (i,j,s)$ denotes sites of the honeycomb lattice with unit cell indices $i,j$ and sublattice $s\in\{A,B\}$, $\sigma_{\mathbf{J}}^\alpha$ are Pauli matrices, and $\kappa$ is a three-site interaction that breaks time-reversal symmetry and drives the system into the gapped chiral non-Abelian phase. The bonds of the honeycomb lattice are partitioned into three sets -- $x$, $y$, and $z$ bonds -- according to their geometric orientations (see Fig.~\ref{fig:ksl_model}), and the Kitaev exchange couplings $\mathcal{J}_x, \mathcal{J}_y, \mathcal{J}_z$ act on the corresponding bond types.

\subsection{Modified Model for Cooling}

To enable efficient cooling, Ref.~\cite{Kishony_2025} introduces a modified KSL Hamiltonian that includes both system ($\sigma$) and auxiliary bath ($\tau$) spins at each site:
\begin{align}
H(t)=\widetilde{H}_{\text{KSL}}+H_{{\rm c}}(t),
\label{eq:H_KSL}
\end{align}
where
\begin{align}
\widetilde{H}_{\text{KSL}}=&-\sum_{\alpha\in\{x,y,z\}}\mathcal{J}_{\alpha}\sum_{\langle \mathbf{I},\mathbf{J}\rangle\in \alpha\text{-bonds}}\sigma_{\mathbf{I}}^{\alpha}\sigma_{\mathbf{J}}^{\alpha}\tau_{\mathbf{I}}^{z}\tau_{\mathbf{J}}^{z}\nonumber\\
&-\kappa\sum_{\langle\langle \mathbf{J},\mathbf{K},\mathbf{L}\rangle\rangle}\sigma_{\mathbf{J}}^x\tau_{\mathbf{J}}^z\sigma_{\mathbf{K}}^y\tau_{\mathbf{K}}^z\sigma_{\mathbf{L}}^z
\label{eq: KSL with spins}
\end{align}

The $\tau^z_{\mathbf{J}}$ operators all commute with $\widetilde{H}_{\rm{KSL}}$. Clearly, $\widetilde{H}_{\text{KSL}}$ is identical to $H_{\text{KSL}}$ in Eq.~\eqref{eq: KSL} in the sector $\tau^z_{\mathbf{J}}=+1$. In fact, the two Hamiltonians are related by a unitary transformation for any state of the $\tau$ spins with even parity, $\prod_{\mathbf{J}} \tau^z_{\mathbf{J}}=1$. To see this, we note that all of the unitary operators $\mathcal{U}_{\mathbf{I},\mathbf{J}} = \tau^x_{\mathbf{I}}\sigma^\alpha_{\mathbf{I}}\sigma^\alpha_{\mathbf{J}}\tau^x_{\mathbf{J}}$, for $\langle \mathbf{I},\mathbf{J}\rangle\in \alpha\text{-bonds}$, commute with $\widetilde{H}_{\rm{KSL}}$ and anticommute individually with $\tau^z_{\mathbf{I}}$ and $\tau^z_{\mathbf{J}}$. The transformation from a sector with a given $\{\tau^z_\mathbf{J}\}$ of even parity to the sector $\tau^z_\mathbf{J}=1$ can be constructed by annihilating pairs of $\tau^z_\mathbf{K},\tau^z_\mathbf{L}=-1$ using a product of the unitaries $\mathcal{U}_{\mathbf{I},\mathbf{J}}$ along a path connecting the points $\mathbf{K}, \mathbf{L}$. Thus, preparing the ground state of $\widetilde{H}_{\rm{KSL}}$ in any known even-parity sector of $\{\tau^z_{\mathbf{J}}\}$ is equivalent to preparing the ground state of the original KSL Hamiltonian, Eq.~\eqref{eq: KSL}.

The control Hamiltonian $H_{{\rm c}}(t)$, which is used to cool into the ground state of $\widetilde{H}_{\text{KSL}}$, is chosen as a time-dependent effective Zeeman field acting on $\tau_{\mathbf{J}}$ with $\hat{x}$ and $\hat{z}$ components:
\begin{align}
H_{{\rm c}}(t)=-\sum_{\mathbf{J}}B(t)s_{\mathbf{J}}\tau_{\mathbf{J}}^{z}-\sum_{\mathbf{J}}g(t)\tau_{\mathbf{J}}^{x},
\label{eq: control hamiltonian}
\end{align}
where the choice of the signs $s_{\mathbf{J}} = \pm 1$ is explained below.

The system is illustrated in Fig.~\ref{fig:ksl_model}, showing the honeycomb lattice with system spins (black) and bath spins (white) at each site, with bonds colored according to their orientation ($x$-blue, $y$-green, $z$-red).

\begin{figure}
\begin{centering}
\includegraphics[width=(\textwidth-\columnsep)/2]{figures/generalized_ksl.pdf}
\par\end{centering}
\caption{\textbf{The generalized KSL model with bath spins.} Each site consists of a system spin (black) and a bath spin (white). The bonds are colored according to orientation: $x$-blue, $y$-green, $z$-red. The five-spin term $\kappa$ drives the system into the chiral phase. The figure shows the structure of the model used for cooling, where auxiliary bath spins enable the fermionic cooling protocol.}
\label{fig:ksl_model}
\end{figure}

\subsection{Fermionization and Momentum-Space Description}

Following Ref.~\cite{Kishony_2025}, we simulataneously fermionize the system and bath spins by introducing a set of six Majorana operators $\{c_{\mathbf{J}}^{x},c_{\mathbf{J}}^{y},c_{\mathbf{J}}^{z},b_{\mathbf{J}}^{x},b_{\mathbf{J}}^{y},b_{\mathbf{J}}^{z}\}$ per site, subject to the constraint
\begin{equation}
c_{\mathbf{J}}^{x}c_{\mathbf{J}}^{y}c_{\mathbf{J}}^{z}b_{\mathbf{J}}^{x}b_{\mathbf{J}}^{y}b_{\mathbf{J}}^{z}=i.
\label{eq:constraint}
\end{equation}

The spin operators are related to the fermionic ones by:
\begin{equation}
\sigma_{\mathbf{J}}^{\alpha}  =-\frac{i}{2}\sum_{\beta,\gamma}\varepsilon^{\alpha\beta\gamma}b_{\mathbf{J}}^{\beta}b_{\mathbf{J}}^{\gamma},\quad
\tau_{\mathbf{J}}^{\alpha}  =-\frac{i}{2}\sum_{\beta,\gamma}\varepsilon^{\alpha\beta\gamma}c_{\mathbf{J}}^{\beta}c_{\mathbf{J}}^{\gamma},
\label{eq: mapping spins to fermions}
\end{equation}
where $\alpha,\beta,\gamma \in \{x,y,z\}$ and $\varepsilon^{\alpha\beta\gamma}$ is the totally antisymmetric tensor.

After fermionization, the Hamiltonian can be expressed in terms of fermions $\{c_{\mathbf{J}}^{x}, c_{\mathbf{J}}^{y}, c_{\mathbf{J}}^{z}\}$ and the conserved $\mathbb{Z}_2$ gauge field $\{u_{\mathbf{I},\mathbf{J}}\}$, where $u_{\mathbf{I},\mathbf{J}} = ib_{\mathbf{I}}^{\alpha}b_{\mathbf{J}}^{\alpha}$ for bonds $\langle \mathbf{I},\mathbf{J}\rangle\in \alpha\text{-bonds}$ with $\alpha\in\{x,y,z\}$. The gauge-invariant flux $W_{i,j}$ of the $\mathbb{Z}_2$ gauge field is defined on each hexagonal plaquette corresponding to unit cell $(i,j)$ as the product of $u_{\mathbf{I},\mathbf{J}}$ on its edges. In the flux-free sector with $W_{i,j}=1$ for all plaquettes (equivalent to setting $u_{\mathbf{I},\mathbf{J}}=1$ up to a $\mathbb{Z}_2$ gauge transformation) and with uniform $\tau^z_{\mathbf{J}}=1$, the Hamiltonian becomes translationally invariant and can be Fourier transformed to momentum space.

The fermionic Hamiltonian in momentum space is:
\begin{align}
H(t)=\sum_{\bm{k}}\bm{\Psi}_{\bm{k}}^\dagger H_{\bm{k}}(t)\bm{\Psi}_{\bm{k}},
\end{align}
where $\bm{\Psi}_{\bm{k}}^\dagger=\begin{pmatrix}c_{(\bm{k},A)}^{z\dagger}&
c_{(\bm{k},B)}^{z\dagger}&
c_{(\bm{k},A)}^{y\dagger}&
c_{(\bm{k},B)}^{y\dagger}&
c_{(\bm{k},A)}^{x\dagger}&
c_{(\bm{k},B)}^{x\dagger}
\end{pmatrix}$,
and the $6 \times 6$ Hamiltonian matrix at each $\bm{k}$ is:
\begin{align}
H_{\bm{k}}(t)=\left(\begin{array}{ccc}
h_{\bm{k}} & -ig(t)\mathbb{I} & 0\\
ig(t)\mathbb{I} & 0 & -iB(t)\mathbb{I}\\
0 & iB(t)\mathbb{I} & 0
\end{array}\right).
\label{eq:Hk}
\end{align}

Here, $h_{\bm{k}}$ is the $2 \times 2$ system Hamiltonian:
\begin{align}
h_{\bm{k}}&=\begin{pmatrix} \Delta(\bm{k}) & if(\bm{k})\\
-if(-\bm{k}) & -\Delta(\bm{k})
\end{pmatrix},
\label{eq:h_k}
\end{align}
where
\begin{align}
\Delta(\bm{k})&=2\kappa\left[\sin{k_x}-\sin{k_y}+\sin{(k_y-k_x)}\right],\\
f(\bm{k})&=\mathcal{J}_{x}+\mathcal{J}_{y}e^{-ik_{x}}+\mathcal{J}_{z}e^{-ik_{y}}.
\end{align}

The key advantage of this momentum-space description is that different $\bm{k}$ points are decoupled, allowing us to analyze the cooling protocol independently at each momentum point.

\subsection{Enlarged Unit Cell and Decomposition of $\kappa$}
\label{sec:enlarged_unit_cell}

The $\kappa$ term as written in Eq.~\eqref{eq:H_KSL} is a sum of terms which do not act on disjoint sets of qubits.
To enable the application of the $\kappa$ term gate-wise in the variational circuit, we partition it into vertex-disjoint subsets by working with an enlarged $2\times2$ supercell structure.
The original unit cell with two sites (one per sublattice) is enlarged to a supercell containing four internal offsets $r_0=(0,0)$, $r_1=(1,0)$, $r_2=(0,1)$, and $r_3=(1,1)$ within each sublattice.
This results in a total of $2 \times 3 \times 4 = 24$ Majorana fermion modes per supercell [2 sublattices $\times$ 3 labels ($x,y,z$) $\times$ 4 offsets].

The three-site $\kappa$ term can be decomposed into $12$ vertex-disjoint subsets, indexed by sublattice class $S\in\{A,B\}$ (A--A or B--B), next-nearest-neighbor direction $d\in\{+i,\,-j,\,j-i\}$, and parity $p\in\{\mathrm{even},\mathrm{odd}\}$. The decomposition is illustrated in Fig.~\ref{fig:kappa_partition}, where different colors represent different subsets that can be applied simultaneously gate-wise.

In the Bloch basis for the supercell, we define $\mathbf{K}\cdot\mathbf{a} = 2K_i$ and $\mathbf{K}\cdot\mathbf{b} = 2K_j$, where $\mathbf{a} = 2\hat{i}$ and $\mathbf{b} = 2\hat{j}$ are the supercell lattice vectors. The system Hamiltonian for the $c^z$ fermions becomes an $8 \times 8$ matrix in this basis, with the structure:
\begin{align}
H(\mathbf{K})=
\begin{pmatrix}
H_{AA} & H_{AB}\\
H_{AB}^\dagger & H_{BB}
\end{pmatrix},
\end{align}
where $H_{AA}$ and $H_{BB}$ contain the $\kappa$ terms (with opposite signs for A and B sublattices), and $H_{AB}$ contains the nearest-neighbor $J$ terms connecting A and B sublattices.

\begin{figure}
\begin{centering}
\includegraphics[width=(\textwidth-\columnsep)/2]{figures/kappa_partition.pdf}
\par\end{centering}
\caption{\textbf{Decomposition of the $\kappa$ term into vertex-disjoint subsets.} The three-site $\kappa$ interactions are partitioned into $12$ commuting blocks. Different colors represent different subsets that can be applied simultaneously as they act on disjoint sets of qubits. Each subset is indexed by sublattice class (A--A or B--B), direction ($+i$, $-j$, or $j-i$), and parity (even or odd).}
\label{fig:kappa_partition}
\end{figure}

\subsection{Cooling Protocol}

The protocol to prepare the ground state of $\widetilde{H}_{\text{KSL}}$ consists of repeated cooling cycles. Each cycle begins with the $\tau$ spins in a known product state in the computational basis (i.e., an eigenstate of all $\tau^z_{\mathbf{J}}$ operators). Before the first cycle, the system is initialized such that $\tau^z_{\mathbf{J}} = +1$ for all sites $\mathbf{J}$. The $\sigma$ spins are brought to a flux-free state, $W_{i,j} = 1$ for all plaquettes. This can be done by measuring all the flux operators (which are mutually commuting) and annihilating the detected fluxes in pairs by applying appropriate local unitary operators.

Each cooling cycle consists of the following stages:

\begin{enumerate}

\item \textbf{Unitary evolution:} The system is evolved unitarily with the time-dependent Hamiltonian $H(t)$ given in Eq.~\eqref{eq:H_KSL}. In the original protocol of Ref.~\cite{Kishony_2025}, during this evolution $g(t)$ and $B(t)$ are adiabatically varied in order to extract energy and entropy from the system to the bath over a time period $T$. The sign of the $B$ field on each site is determined by the orientation of the $\tau$ spins at the beginning of the cycle: $B_{\mathbf{J}}(t) = B(t) s_{\mathbf{J}}$, where $s_{\mathbf{J}} = \pm 1$ is the eigenvalue of $\tau^z_{\mathbf{J}}$ at the start of the cycle.

\item \textbf{Measurement and update of $s_\mathbf{J}$:} At the end of the cycle, the $\tau^z_{\mathbf{J}}$ operators are measured in the computational basis, giving new eigenvalues $\{\tau^z_{\mathbf{J}}\}$. This measurement projects the $\tau$ spins back to a product state and relates the prepared state to the ground state of the original KSL model through the unitary equivalence discussed above. The measurement outcomes determine the signs $s_{\mathbf{J}}$ used in the $B$ field term for the next cycle.
\end{enumerate}

The cycle is repeated until convergence to a low energy steady state is achieved.

\subsection{Variational Circuit}

Rather than implementing the full continuous-time adiabatic evolution through many Trotter steps, we replace the unitary evolution stage (step 1) of the protocol with a shallow-depth variational circuit with $p$ layers. The other stages of the protocol (flux preparation, measurement, and update of $s_\mathbf{J}$) remain unchanged.

\subsubsection{Circuit Structure}

The variational circuit replaces the continuous-time adiabatic evolution with a product of $p$ layers, where each layer applies unitary gates corresponding to the different terms in the Hamiltonian:

\begin{align}
U_{\text{cycle}} = \prod_{\ell=1}^{p} U_\ell,
\end{align}
where each layer $U_\ell$ consists of:
\begin{align}
U_\ell = U_B(\beta_\ell) \, U_g(\gamma_\ell) \, U_{\kappa}(\delta_\ell) \, U_{J_z}(\alpha_{z,\ell}) \, U_{J_y}(\alpha_{y,\ell}) \, U_{J_x}(\alpha_{x,\ell}).
\label{eq:layer}
\end{align}

Each term corresponds to exponentiation of the corresponding Hamiltonian component:
\begin{itemize}
\item $U_{J_x}(\alpha_{x,\ell}) = \exp\left(-i (\alpha_{x,\ell}/2) \sum_{\langle \mathbf{I},\mathbf{J}\rangle\in x\text{-bonds}}\sigma_{\mathbf{I}}^{x}\sigma_{\mathbf{J}}^{x}\tau_{\mathbf{I}}^{z}\tau_{\mathbf{J}}^{z}\right)$ for the $J_x$ bond interactions
\item $U_{J_y}(\alpha_{y,\ell}) = \exp\left(-i (\alpha_{y,\ell}/2) \sum_{\langle \mathbf{I},\mathbf{J}\rangle\in y\text{-bonds}}\sigma_{\mathbf{I}}^{y}\sigma_{\mathbf{J}}^{y}\tau_{\mathbf{I}}^{z}\tau_{\mathbf{J}}^{z}\right)$ for the $J_y$ bond interactions  
\item $U_{J_z}(\alpha_{z,\ell}) = \exp\left(-i (\alpha_{z,\ell}/2) \sum_{\langle \mathbf{I},\mathbf{J}\rangle\in z\text{-bonds}}\sigma_{\mathbf{I}}^{z}\sigma_{\mathbf{J}}^{z}\tau_{\mathbf{I}}^{z}\tau_{\mathbf{J}}^{z}\right)$ for the $J_z$ bond interactions
\item $U_{\kappa}(\delta_\ell) = \prod_{S,d,p} \exp\left(-i (\delta_\ell/2) H_{\kappa}^{S,d,p}\right)$ for the three-site $\kappa$ term, where the product is over the $12$ vertex-disjoint subsets $H_{\kappa}^{S,d,p}$ (see Fig.~\ref{fig:kappa_partition}). Each subset $H_{\kappa}^{S,d,p}$ acts on disjoint sets of qubits.
\item $U_g(\gamma_\ell) = \exp\left(-i (\gamma_\ell/2) \sum_{\mathbf{J}}\tau_{\mathbf{J}}^{x}\right)$ for the system-bath coupling
\item $U_B(\beta_\ell) = \exp\left(-i (\beta_\ell/2) \sum_{\mathbf{J}}s_{\mathbf{J}}\tau_{\mathbf{J}}^{z}\right)$ for the bath Zeeman field, where $s_{\mathbf{J}} = \pm 1$ is the measurement outcome of $\tau^z_{\mathbf{J}}$ from the previous cycle
\end{itemize}

The variational parameters $\{\alpha_{x,\ell}, \alpha_{y,\ell}, \alpha_{z,\ell}, \beta_\ell, \gamma_\ell, \delta_\ell\}_{\ell=1}^p$ are all periodic modulo $2\pi$, and are optimized to minimize the energy density in the steady state achieved after multiple cooling cycles.

\section{Training Regimen}

\subsection{Goals}

The goals of training are to optimize the circuit's parameters to:
\begin{enumerate}
\item[(i)] achieve a low steady state energy density with respect to the ground state,
\item[(ii)] achieve this with a small number of layers, $p$, per cycle,
\item[(iii)] achieve rapid convergence, such that energy converges toward the steady state in as few cycles as possible,
\item[(iv)] ensure scalability, such that parameters trained on small training system sizes transfer well to larger testing system sizes.
\end{enumerate}

Keeping the numbers of required layers and cycles small is particularly important for implementation on NISQ hardware, where errors can build up for large depth circuits. The non-unitary protocol exhibits an inherent robustness to noise through transfer and elimination of excitations through the bath qubits; the steady state is most resilient to hardware noise when cooling is rapid and the depth $p$ of each unitary block is small.

\subsection{Loss Function}

For computational efficiency, we train the protocol on a small system of size $L_{\text{train}} \times L_{\text{train}}$ enlarged unit cells. Later, we evaluate the performance of the trained circuit a larger system of size $L_{\text{test}} \times L_{\text{test}}$ enlarged unit cells.

The loss function for training is computed as follows. For each momentum point $\bm{k}$ in the training system Brillouin zone, we simulate $T_{\text{train}}$ cycles of cooling starting from a maximally mixed initial state. The energy $E(\bm{k})$ after $T_{\text{train}}$ cycles is computed at each $\bm{k}$ point, and the loss function is defined as the root-mean-square (RMS) energy difference from the ground state:
\begin{align}
\mathcal{L} = \frac{1}{2L_{\text{train}}^2}\sqrt{\sum_{\bm{k}} \left(E(\bm{k}) - E_0(\bm{k})\right)^2},
\end{align}
where $E_0(\bm{k})$ is the ground state energy at momentum point $\bm{k}$, and the factor of $1/2$ accounts for the fact that we count both $\bm{k}$ and $-\bm{k}$ in our summation over the full Brillouin zone. The RMS loss is chosen because it penalizes large energy deviations more strongly than the mean absolute error, ensuring that the protocol performs well across the entire Brillouin zone rather than just on average.
As discussed in Ref.~\cite{song2025varicoolnonunitaryquantumvariational}, minimizing the loss function after a few cycles of cooling ballances the trade-off between goals (i) and (iii) above.

\subsection{Progressive Circuit Expansion}

A key strategy in our training approach is the progressive expansion of the circuit depth. Direct optimization of parameters for a target circuit depth $p$ can be challenging due to barren plateaus~\cite{Cerezo2021} and local minima in the optimization landscape. Instead, we start with a small circuit depth $p_{\min}$ and progressively expand the circuit depth to $p$ by inserting new layers. This provides a warm start that typically leads to better convergence than random initialization.

\begin{enumerate}
\item For the smallest $p$ value ($p_{\min}$), we use a global optimization method (basin hopping) to avoid getting trapped in local minima. This global optimizer explores the parameter space more thoroughly and is appropriate for the smallest circuit depth where the parameter space is small.
\item For each subsequent $p > p_{\min}$, we expand the previous optimized circuit by inserting a new layer of gates with zero-valued parameters in the middle of the previous layers. This provides a warm start that typically leads to better convergence than random initialization at the larger circuit depth.
\item The expanded circuit is then re-optimized using a local optimization method (the L-BFGS-B method from SciPy), allowing the newly inserted layers to develop non-zero values as needed. The warm start from the expanded circuit makes local optimization effective for these larger circuit depths.
\end{enumerate}

This approach, allows us to systematically explore increasing circuit depths while leveraging the optimization work done at smaller depths.

\section{Results}

Throughout this section, we present results for the chiral phase of the Kitaev spin liquid model with exchange couplings $\mathcal{J}_x = \mathcal{J}_y = \mathcal{J}_z = 1$ and three-site interaction strength $\kappa = 1$.
Before cooling, the system is initialized in a maximally mixes state. We use $T_{\text{train}} = 5$ cooling cycles to train the circuit.
We use the state reached after $T_{\text{steady}} = 40$ cooling cycles as a proxy for the steady state.
Various system sizes $L_{\text{train}}$ are used for training. The performance is evaluated on a test system of size $L_{\text{test}} = 120$.

\subsection{Energy vs. Circuit Depth}

\begin{figure}
\begin{centering}
\includegraphics[width=(\textwidth-\columnsep)/2]{figures/energy_vs_p_by_res_24x24.pdf}
\par\end{centering}
\caption{\textbf{Energy density vs. circuit depth $p$ for different training system sizes.} Solid lines show test grid performance, dashed lines show training grid performance. Results are shown for various training system sizes. The protocol achieves near-optimal performance even with $p=5$ layers.}
\label{fig:energy_vs_p}
\end{figure}

Fig.~\ref{fig:energy_vs_p} shows the energy density as a function of circuit depth $p$ for different training system sizes evaluated for both the training and test system sizes.
When the training system size is small, the training protocol overfits to the training system and the trained circuits perform poorly on the test system.
However, as the training system size increases, the gap in performance between the training and test system sizes vanishes.
We observe that even with $p=5$ layers, the protocol achieves performance comparable to much deeper circuits, demonstrating the effectiveness of the variational optimization.

\subsection{Finite Size Spectral Chern Number vs. Circuit Depth}

To probe the convergence to the ground state, we compute the finite size spectral Chern number $\nu$ of the single-particle density matrix $R$ of the system fermions, where $R_{s,s'}(\bm{k})=\left\langle c_{(\bm{k},s)}^{z\dagger} c_{(\bm{k},s')}^{z}\right\rangle$. We use a generalization of the formula of Ref.~\cite{Fukui_2005} for the case of non-pure density matrices. On a discrete momentum-space grid, we evaluate the phase accumulated around each plaquette $\Phi_{\square}(\bm{k}) = \arg\left[\mathrm{Tr}\left(R(\bm{k}) R(\bm{k}+\delta\bm{k}_x) R(\bm{k}+\delta\bm{k}_x+\delta\bm{k}_y) R(\bm{k}+\delta\bm{k}_y)\right)\right]$, where $\delta\bm{k}_x$ and $\delta\bm{k}_y$ are the grid spacings. The Chern number is then $\nu = (2\pi)^{-1}\sum_{\bm{k}} \Phi_{\square}(\bm{k})$. 
This formula yields a continuous (non-quantized) value for mixed states and reduces to the quantized integer value in a pure state, expected to be $\nu=1$ in the ground state of the KSL model.

Fig.~\ref{fig:chern_vs_p} shows the finite size spectral Chern number $\nu$ of the prepared steady state as a function of circuit depth. As the circuit depth increases, the steady state value of the Chern number rapidly approaches $\nu=1$.

\begin{figure}
\begin{centering}
\includegraphics[width=(\textwidth-\columnsep)/2]{figures/chern_vs_p_24x24.pdf}
\par\end{centering}
\caption{\textbf{Finite size spectral Chern number $\nu$ vs. circuit depth $p$ for different training system sizes.} Solid lines show test system performance, dashed lines show training system performance. The target value is $\nu=1$ for the system fermions. Results are shown for various training system sizes. The protocol successfully prepares states with the correct topological invariant even with shallow circuits.}
\label{fig:chern_vs_p}
\end{figure}

\subsection{Energy Convergence vs. Cycles}

\begin{figure}
\begin{centering}
\includegraphics[width=(\textwidth-\columnsep)/2]{figures/energy_vs_cycles_24x24.pdf}
\par\end{centering}
\caption{\textbf{Energy density vs. number of cooling cycles for trained circuit with $L_{\text{train}} = 18$, $p=5$.} Results are shown for both training system size (blue) and test system size (red). The protocol converges to a steady state within a few cycles.}
\label{fig:energy_vs_cycles}
\end{figure}

Fig.~\ref{fig:energy_vs_cycles} demonstrates the convergence of the energy density as a function of the number of cooling cycles. The protocol rapidly approaches its steady state, with most of the cooling occurring within the first cycle.
In the adiabatic limit, the protocol of Ref.~\cite{Kishony_2025} is able to reach the ground state within a single cycle. Here, using a much lower depth circuit, the protocol takes advantage of the repeated cooling cycles to reach a lower energy steady state than could be reached in a single cycle.

\subsection{Energy Heatmaps}

\begin{figure}
\begin{centering}
\includegraphics[width=(\textwidth-\columnsep)/2]{figures/energy_heatmap_train_24x24.pdf}\\
\vspace{0.2cm}
\includegraphics[width=(\textwidth-\columnsep)/2]{figures/energy_heatmap_test_24x24.pdf}
\par\end{centering}
\caption{\textbf{Energy difference heatmaps for optimized circuit with $L_{\text{train}} = 18$, $p=5$.} (Top) Training grid. (Bottom) Test grid, with red crosses indicating the training grid points for comparison. The color scale shows the energy difference from the ground state at each momentum point. The protocol successfully cools the system across the entire Brillouin zone, with only small residual excitations remaining.}
\label{fig:energy_heatmap}
\end{figure}

Fig.~\ref{fig:energy_heatmap} shows the distribution of energy differences in momentum space on both the training and test grids. The protocol successfully cools the system across the entire Brillouin zone, with only small residual excitations remaining.

\subsection{Optimized Parameters}

\begin{figure}
\begin{centering}
\includegraphics[width=(\textwidth-\columnsep)/2]{figures/parameters_vs_layer_24x24.pdf}
\par\end{centering}
\caption{\textbf{Optimized variational parameters vs. layer number $\ell$ for circuit with $L_{\text{train}} = 18$, $p=5$.}
Different colors represent different parameter types: $\alpha_{x,\ell}$ ($J_x$), $\alpha_{y,\ell}$ ($J_y$), $\alpha_{z,\ell}$ ($J_z$), $\beta_\ell$ ($B$), $\gamma_\ell$ ($g$), and $\delta_\ell$ ($\kappa$), where $\ell = 1, \ldots, p$ indexes the layers.}
\label{fig:parameters_vs_layer}
\end{figure}

Fig.~\ref{fig:parameters_vs_layer} displays the optimized variational parameters as a function of layer index for the circuit with $L_{\text{train}} = 18$, $p=5$.

\section{Discussion}

Our results demonstrate that variational optimization can dramatically compress the depth of fermionic cooling circuits while maintaining high fidelity ground state preparation.

Future directions include extending this approach to interacting fermionic systems, exploring different circuit ans√§tze, and investigating the performance on quantum hardware with noise.

% \begin{acknowledgements}
% G.K. was supported by CRC 183 of the Deutsche Forschungsgemeinschaft (subproject A01), a research grant from the Estate of Gerald Alexander, and ISF-MAFAT Quantum Science and Technology Grant no. 2478/24.
% \end{acknowledgements}

\bibliography{References.bib}

\end{document}

